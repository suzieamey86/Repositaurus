{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will be working with a data set of submissions to the popular techonology site [Hacker News](https://news.ycombinator.com/), which was started by the startup incubator [Y Combinator](https://www.ycombinator.com/).  On this site, user-submitted stories, or posts, are voted and commented on by readers.  Hacker News is extremely popular in technology and start up circles, and posts which make it to the top of their listings often get hundreds of thousands of visitors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set which will be used in this project can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts).  Please not that the data set has been reduced from almost 300,000 entries to approximately 20,000 by removing any posts that didn't receive any comments, and then randomly sampling the remaining entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns for each post are described as follows:\n",
    "\n",
    "- `id` : The unique identifier from Hacker News for the post\n",
    "- `title` : The title of the post\n",
    "- `url` : The URL that the post links to, if it has a URL\n",
    "- `num_points` : The number of points the post acquired, calculated as the total number of upvotes, minus the total number of downvotes\n",
    "- `num_comments` : The number of comments that were made on the post\n",
    "- `author` : The username of the person who submitted the post\n",
    "- `created_at` : The date and time at which the post was submitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be analysing posts whose titles begin with either `Ask HN` or `Show HN`.  Users submit `Ask HN` posts to ask the Hacker News community a specific question, for example:\n",
    "\n",
    "- `Ask HN: How to improve my personal website?`\n",
    "- `Ask HN: Am I the only one outraged by Twitter shutting down share counts?`\n",
    "- `Ask HN: Any recent changes to CSS that broke mobile?`\n",
    "\n",
    "`Show HN` posts are submitted to show the Hacker News community a project, product, or just generally something interesting, for example:\n",
    "\n",
    "- `Show HN: Wio Link ESP8266 Based Web of Things Hardware Development Platform`\n",
    "- `Show HN: Something pointless I made`\n",
    "- `Show HN: Shanhu.io, a programming playground powered by e8vm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the two types of posts to determine the following:\n",
    "\n",
    "- Do `Ask HN` or `Show HN` posts receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "We'll start by importing the libraries we need and reading the data set into a list of lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening and Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn_data = list(read_file)\n",
    "headers = hn_data[0]\n",
    "hn = hn_data[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a function to simplify exploring the data set, called **explore_data()**, which will print the rows in an easily-readable format and also has the option to show the number of rows and columns for the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns = False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "Number of rows: 20101\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "explore_data(hn_data, 0, 5, rows_and_columns = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can filter our data to find only the post titles beginning with `Ask HN` or `Show HN` and create a new list of lists containing the data for only these titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Average Number of Comments for Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's determine whether ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average comments for ask posts: 14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    comments = row[4]\n",
    "    total_ask_comments += int(comments)\n",
    "\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "\n",
    "print('Average comments for ask posts:', avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average comments for show posts: 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    comments = row[4]\n",
    "    total_show_comments += int(comments)\n",
    "    \n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "\n",
    "print('Average comments for show posts:', avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculations above show that `Ask HN` posts receive an average of 14 comments per post, and `Show HN` posts receive an average of 10 comments per post.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've found that, on average, `Ask HN` posts receive more comments than `Show HN` posts, we will focus our remaining analysis on just these posts.\n",
    "\n",
    "Next, we'll determine whether ask posts created at certain times are likely to attract more comments than others.\n",
    "\n",
    "To do this, we will:\n",
    "\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Amount of Ask Posts and Comments by Hour Created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a list called `result_list`, with each row consisting of the time that the post was created plus the number of comments the post received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    created = row[6] ## the time at which the post was created\n",
    "    comments = int(row[4]) ## the number of comments the post received\n",
    "    result_list.append([created, comments])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will create two dictionaries: \n",
    "\n",
    "- `counts_by_hour`: shows the number of ask posts created during each hour of the day\n",
    "- `comments_by_hour`: contains the corresponding number of comments that ask posts created at each hour received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 447,\n",
       " '01': 683,\n",
       " '02': 1381,\n",
       " '03': 421,\n",
       " '04': 337,\n",
       " '05': 464,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '08': 492,\n",
       " '09': 251,\n",
       " '10': 793,\n",
       " '11': 641,\n",
       " '12': 687,\n",
       " '13': 1253,\n",
       " '14': 1416,\n",
       " '15': 4477,\n",
       " '16': 1814,\n",
       " '17': 1146,\n",
       " '18': 1439,\n",
       " '19': 1188,\n",
       " '20': 1722,\n",
       " '21': 1745,\n",
       " '22': 479,\n",
       " '23': 543}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comment = row[1]\n",
    "    date_dt = dt.datetime.strptime(date, '%m/%d/%Y %H:%M')\n",
    "    hour = date_dt.strftime('%H')\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comment\n",
    "    else:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comment    \n",
    "        \n",
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Average Number of Comments for Ask HN Posts by Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use the two dictionaries created above to calculate the average number of comments for `Ask HN` posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['22', 6.746478873239437],\n",
       " ['17', 11.46],\n",
       " ['12', 9.41095890410959],\n",
       " ['23', 7.985294117647059],\n",
       " ['08', 10.25],\n",
       " ['07', 7.852941176470588],\n",
       " ['13', 14.741176470588234],\n",
       " ['19', 10.8],\n",
       " ['11', 11.051724137931034],\n",
       " ['04', 7.170212765957447],\n",
       " ['10', 13.440677966101696],\n",
       " ['02', 23.810344827586206],\n",
       " ['16', 16.796296296296298],\n",
       " ['01', 11.383333333333333],\n",
       " ['03', 7.796296296296297],\n",
       " ['09', 5.5777777777777775],\n",
       " ['21', 16.009174311926607],\n",
       " ['14', 13.233644859813085],\n",
       " ['06', 9.022727272727273],\n",
       " ['18', 13.20183486238532],\n",
       " ['20', 21.525],\n",
       " ['15', 38.5948275862069],\n",
       " ['00', 8.127272727272727],\n",
       " ['05', 10.08695652173913]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hr in comments_by_hour:\n",
    "        avg_by_hour.append([hr, comments_by_hour[hr]/counts_by_hour[hr]])\n",
    "        \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting and Printing Values from a List of Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now obtained the results that we need, but they are in a format which is difficult to make sense of.  We can finish off by sorting the `avg_by_hour` list of lists and printing the five highest values in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will swap the columns in `avg_by_hour` so that the first element becomes the second element, and vice versa; then, we can arrange them in descending order, so that the hours with the highest average number of comments per post are at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.746478873239437, '22'], [11.46, '17'], [9.41095890410959, '12'], [7.985294117647059, '23'], [10.25, '08'], [7.852941176470588, '07'], [14.741176470588234, '13'], [10.8, '19'], [11.051724137931034, '11'], [7.170212765957447, '04'], [13.440677966101696, '10'], [23.810344827586206, '02'], [16.796296296296298, '16'], [11.383333333333333, '01'], [7.796296296296297, '03'], [5.5777777777777775, '09'], [16.009174311926607, '21'], [13.233644859813085, '14'], [9.022727272727273, '06'], [13.20183486238532, '18'], [21.525, '20'], [38.5948275862069, '15'], [8.127272727272727, '00'], [10.08695652173913, '05']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will print out the top 5 hours for comments on `Ask HN` posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "\n",
    "for avg, hr in sorted_swap[:5]:\n",
    "    print(\"{}: {:.2f} average comments per post\".format(dt.datetime.strptime(hr, '%H').strftime('%H:%M'),avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show us that the posts posted at 15:00 received the highest number of comments, with an average of 38.59 comments per post.  The next hour down the list is 02:00, which has an average of 21.52 comments per post - nearly 60% less than the highest.\n",
    "\n",
    "When we look at the data set [documentation](https://www.kaggle.com/hacker-news/hacker-news-posts/), it tells us that the time zone for each post is Eastern Standard Time in the US, so we could write the time as 3pm EST so that readers can work out what the equivalent time in their time zone would be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we were looking at posts on the `Hacker News` website, with the aim of determining which posts gained the highest number of comments on average.  \n",
    "\n",
    "We analysted the data to find out whether, *of the posts which received any comments*:\n",
    "\n",
    "- `Ask HN` or `Show HN` posts received the most comments\n",
    "- posts posted at a particular time of day received more comments than others\n",
    "\n",
    "We have come to the conclusion that the most commented on posts are `Ask HN` posts posted between 3pm - 4pm EST."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
