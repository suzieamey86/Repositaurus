{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building a Database for Crime Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will be applying what I have learnt to build a database for storing data related to crimes that occured in Boston.  The dataset which will be used is stored in a file called `boston.csv`.\n",
    "\n",
    "The first four rows of the database are shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://github.com/suzieamey86/Repositaurus/blob/images/Boston%20Crime%20Data.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A description of the columns is as follows:\n",
    "\n",
    "- `incident_number`:  An identifier of the crime\n",
    "- `offense_code`:  A numeric identifier code for the committed crime\n",
    "- `description`:  A description of the crime\n",
    "- `date`:  The date on which the crime took place\n",
    "- `day_of_the_week`:  The day of the week on which the crime took place\n",
    "- `lat`:  The latitude coordinate at which the crime occurred\n",
    "- `long`:  The longitude coordinate at which the crime occurred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the project is to create a database named `crimes_db`, with a table - `boston_crimes` - with appropriate datatypes for storing data from the `boston.csv` file.  The table will be created inside a schema named `crimes`.  I will also create two groups: `readonly` and `readwrite`, with the appropriate privileges assigned to each one.  Finally, one user for each group will be created.\n",
    "\n",
    "The diagram below shows a high level overview of what will be achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://github.com/suzieamey86/Repositaurus/blob/images/Crime%20Database%20Overview.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creating the Crime Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start by creating a database named `crime_db` to store the crime data, and a shema named `crimes` to keep the data organised in tables.\n",
    "\n",
    "In order to create a database, the connection needs to be set to:\n",
    "\n",
    "- `connection.autocommit = True`\n",
    "\n",
    "This is because the creation of a database must be executed straightaway by itself, rather than in a transaction block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "### connect to db 'dq' and create new db ###\n",
    "\n",
    "conn = psycopg2.connect(dbname = \"dq\", user = \"dq\")\n",
    "cur = conn.cursor()\n",
    "conn.autocommit = True\n",
    "cur.execute(\"CREATE DATABASE crime_db;\")\n",
    "\n",
    "### set autocommit to False after creating new db ###\n",
    "\n",
    "conn.autocommit = False \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### connect to `crime_db` and create new db schema ###\n",
    "\n",
    "conn = psycopg2.connect(dbname = \"crime_db\", user = \"dq\")\n",
    "conn.rollback()\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE SCHEMA crimes;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the Column Names and Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can start creating tables.  First, I will look at a sample of the data so that I can decide on which datatypes to use.\n",
    "\n",
    "I will read the header row and the first data row from the `boston.csv` file and inspect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
      "\n",
      "\n",
      "['1', '619', 'LARCENY ALL OTHERS', '2018-09-02', 'Sunday', '42.35779134', '-71.13937053']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "### open the file using csv reader and assign a header row ###\n",
    "\n",
    "with open(\"boston.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    rows = list(reader)\n",
    "    col_headers = rows[0]\n",
    "    first_row = rows[1]\n",
    "\n",
    "print(col_headers)\n",
    "print('\\n')\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creating an Auxiliary Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating a table to store the crime data, I need to identify the correct datatypes for each column.  In order to do that, I'm going to create a function named `get_col_value_set()`, which will return a Python set with all distinct values in a column when given the name of a CSV file and the column's index.\n",
    "\n",
    "This function will be useful to:\n",
    "\n",
    "- Check whether a column can be represented using an enumerated datatype.\n",
    "- Calculate the maximum length of any text-like column in order to set an appropriate size for a `VARCHAR` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incident_number :  298329\n",
      "offense_code :  219\n",
      "description :  239\n",
      "date :  1177\n",
      "day_of_the_week :  7\n",
      "lat :  18177\n",
      "long :  18177\n"
     ]
    }
   ],
   "source": [
    "### create function to find distinct values in a given column ###\n",
    "\n",
    "def get_col_value_set(csv_filename, col_index):\n",
    "    import csv\n",
    "    col_values = set()\n",
    "    with open(csv_filename, \"r\") as f:\n",
    "        next(f)\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            col_values.add(row[col_index])\n",
    "    return col_values\n",
    "\n",
    "for i in range(len(col_headers)):\n",
    "    col_values = get_col_value_set(\"boston.csv\", i)\n",
    "    print(col_headers[i], \": \", len(col_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Maximum Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got the number of distinct values for each column, we can see that `day_of_the_week` has only got 7 distinct values so would be a good candidate for an enumerated datatype, where the datatype contains only these distinct values, preventing any other value from being entered into the column.\n",
    "\n",
    "For columns with textual data, it is important to find out the length of the longest word they contain so that we can set a maximum `VARCHAR` length.  The two columns with textual data are `day_of_the_week` and `description`. As I have decided to use an enumerated datatype for the `day_of_the_week` column, I only need to find the longest word in the `description` column, I will use the `get_col_value_set` function to get a set of distinct values in the `description` column (index[2]) and iterate over each element to find out which word is the longest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description max length:  58\n"
     ]
    }
   ],
   "source": [
    "### find maximum word length in `description` column ###\n",
    "\n",
    "description_vals = get_col_value_set(\"boston.csv\", 2)\n",
    "max_len = 0\n",
    "for val in description_vals:\n",
    "    if len(val) > max_len:\n",
    "        max_len = len(val)\n",
    "        \n",
    "print(\"description max length: \", max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creating the Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I will now create a table named `boston_crimes` inside the `crimes` schema of the `crime_db` database.  As I have decided to use an enumerated datatype for the `day_of_the_week` column, I will do this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### create enumerated datatype for `day_of_the_week` ###\n",
    "\n",
    "cur.execute(\"\"\"CREATE TYPE days_of_week AS ENUM\n",
    "                ('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday',\n",
    "                    'Saturday', 'Sunday');\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will print the values of `col_headers` to remind myself of the information in each column and choose suitable column names for the table, and also print the first 5 data rows, and the last data row, to see what kind of data is contained in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
      "\n",
      "\n",
      "['1', '619', 'LARCENY ALL OTHERS', '2018-09-02', 'Sunday', '42.35779134', '-71.13937053']\n",
      "\n",
      "\n",
      "['2', '1402', 'VANDALISM', '2018-08-21', 'Tuesday', '42.30682138', '-71.06030035']\n",
      "\n",
      "\n",
      "['3', '3410', 'TOWED MOTOR VEHICLE', '2018-09-03', 'Monday', '42.34658879', '-71.07242943']\n",
      "\n",
      "\n",
      "['4', '3114', 'INVESTIGATE PROPERTY', '2018-09-03', 'Monday', '42.33418175', '-71.07866441']\n",
      "\n",
      "\n",
      "['5', '3114', 'INVESTIGATE PROPERTY', '2018-09-03', 'Monday', '42.27536542', '-71.09036101']\n",
      "\n",
      "\n",
      "['298329', '3125', 'WARRANT ARREST', '2015-06-22', 'Monday', '42.33383935', '-71.08029038']\n"
     ]
    }
   ],
   "source": [
    "print(col_headers)\n",
    "print('\\n')\n",
    "for row in rows[1:6]:\n",
    "    print(row)\n",
    "    print('\\n')\n",
    "print(rows[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of the columns in the new table and their datatypes will be:\n",
    "\n",
    "- Incident_Number: integer\n",
    "- Offense_Code: smallint\n",
    "- Description_of_Crime: varchar(100)\n",
    "- Date_of_Crime: date\n",
    "- Day_of_Crime: Enumerated (`days_of_week`)\n",
    "- Latitude: decimal (10, 8)\n",
    "- Longitude: decimal (11, 8)\n",
    "\n",
    "My reasons for datatype selection are:\n",
    "\n",
    "- Incident_Number: This column contains a number identifying the crime, it starts from the number 1 and, I can see from the last row of data printed above, that it goes up to the number 298329.  As the integer datatype has a range of -2147483648 to +2147483647, it will be able to accomodate the highest number in this column.\n",
    "- Offense_Code: The numbers in this column look to be either 3 or 4 digits long, easily accomodated by the smallint range of -32768 to +32767.\n",
    "- Description of Crime: We calculated previously that the longest entry in this column is 58 characters long.  I have given the varchar a maximum value of 100 to allow some margin but still keep the memory requirement fairly small.\n",
    "- Date_of_Crime: This is fairly self-explanatory. A standard date format can be used.\n",
    "- Day_of_Crime: I have created the enumerated datatype `days_of_week` for this column.\n",
    "- Latitude: The highest possible value for a latitude coordinate is -90 or +90, so there will be no more than two digits before the decimal place.  The values I can see from the data sample show an accuracy of 8 digits after the decimal place.\n",
    "- Longitude: The higest possible value for a longitude coordinate is -180 or +180, so I have given this decimal datatype a precision of 11, and again, a score of 8 digits after the decimal place.\n",
    "\n",
    "Now I can go ahead and create the table with the correct datatype for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create `boston_crimes` table within the `crimes` schema ###\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "        CREATE TABLE crimes.boston_crimes (\n",
    "            Incident_Number integer PRIMARY KEY,\n",
    "            Offense_Code smallint,\n",
    "            Description_of_Crime varchar(100),\n",
    "            Date_of_Crime date,\n",
    "            Day_of_Crime days_of_week,\n",
    "            Latitude decimal(10, 8),\n",
    "            Longitude decimal(11, 8)\n",
    "        );\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the `boston_crimes` table has been created, I can load the data from the `boston.csv` file into it. \n",
    "\n",
    "I am going to use the `cursor.copy_expert()` method to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298329\n"
     ]
    }
   ],
   "source": [
    "### load data into `boston_crimes` table from `boston.csv` ###\n",
    "\n",
    "with open(\"boston.csv\", \"r\") as f:\n",
    "    cur.copy_expert(\"COPY crimes.boston_crimes FROM STDIN WITH CSV HEADER;\", f)\n",
    "\n",
    "### print the no. of table rows to check data loaded correctly ###\n",
    "\n",
    "cur.execute(\"SELECT * FROM crimes.boston_crimes\")\n",
    "print(len(cur.fetchall()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have now got 298329 rows of data in the `crimes.boston_crimes` table, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revoking Public Privileges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating my two user groups, namely `readonly` and `readwrite`, I want to ensure that no privileges can be inherited from the `public` group and `public` schema to any other group or schema, so I will revoke all privileges on the `public` group and schema.  This practice follows the privilege of least principle, where any user or group should only have the least amount of access necessary for their role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### revoke all privileges from `public` group and schema ###\n",
    "\n",
    "cur.execute(\"REVOKE ALL ON SCHEMA public FROM public;\")\n",
    "\n",
    "cur.execute(\"REVOKE ALL ON DATABASE crime_db FROM public;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating User Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can create the two user groups; these are `readonly`, where users will only be able to read data, so will only have privileges to perform `SELECT` queries, and `readwrite`, where users will have privileges to perform `SELECT`, `INSERT`, `DELETE` and `UPDATE` queries, so, they can read and alter data but not delete any tables.\n",
    "\n",
    "I will create the user groups with `NOLOGIN` because log-in details should be given to individual users rather than groups.\n",
    "\n",
    "Both user groups will also need connection privileges to the `crime_db` database, otherwise they won't be able to connect or do anything at all with this database, and they will need to be granted usage of the `crimes` schema within the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### create `readonly` and `readwrite` user groups ###\n",
    "\n",
    "cur.execute(\"CREATE GROUP readonly NOLOGIN;\")\n",
    "cur.execute(\"CREATE GROUP readwrite NOLOGIN;\")\n",
    "\n",
    "### grant `CONNECT` to crime_db and USAGE to `crimes` schema for both groups ###\n",
    "\n",
    "cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readonly;\")\n",
    "cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readwrite;\")\n",
    "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readonly;\")\n",
    "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readwrite;\")\n",
    "\n",
    "### grant group specific privileges to each group for all tables in `crimes` schema ###\n",
    "\n",
    "cur.execute(\"GRANT SELECT ON ALL TABLES IN SCHEMA crimes TO readonly;\")\n",
    "cur.execute(\"GRANT SELECT, INSERT, DELETE, UPDATE ON ALL TABLES IN SCHEMA crimes TO readwrite;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Users "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will create one user for each of the new user groups with individual user names and passwords:\n",
    "\n",
    "- readonly: user = \"data_analyst\", password = \"secret1\"\n",
    "- readwrite: user = \"data_scientist\", password = \"secret2\"\n",
    "\n",
    "Each user also needs to be granted the privileges for the correct user group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### create a user for each new user group ###\n",
    "\n",
    "cur.execute(\"CREATE USER data_analyst WITH PASSWORD 'secret1';\")\n",
    "cur.execute(\"GRANT readonly TO data_analyst;\")\n",
    "cur.execute(\"CREATE USER data_scientist WITH PASSWORD 'secret2';\")\n",
    "cur.execute(\"GRANT readwrite TO data_scientist;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database is now set up with a schema, a table, two user groups and a user for each user group.  It is good practice to test that everything is configured as expected once the set-up is complete.  To do this, we can query Postgres internal tables to check that objects have been created and users and groups have been assigned the correct privileges.\n",
    "\n",
    "I will query the `pg_roles` table to inspect the privileges related to the database, the columns I will select are:\n",
    "\n",
    "- rolname: the role name\n",
    "- rolsuper: states whether the role has superuser privileges\n",
    "- rolcreaterole: whether the group can create other roles\n",
    "- rolcreatedb: whether the group can create databases \n",
    "- rolcanlogin: whether the user/group can log in\n",
    "\n",
    "`rolsuper`, `rolcreaterole`, and `rolcreatedb` are expected to be False for both groups and both users which have been created, and `rolcanlogin` is expected to be False for the two groups but True for the two users.\n",
    "\n",
    "To inspect the table privileges, I will query the following columns in the `information_schema.table_privileges` table:\n",
    "\n",
    "- grantee: name of the role that the privilege was granted to\n",
    "- privilege_type: type of the privilege that was granted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('readonly', False, False, False, False)\n",
      "('readwrite', False, False, False, False)\n",
      "('data_analyst', False, False, False, True)\n",
      "('data_scientist', False, False, False, True)\n",
      "\n",
      "\n",
      "('readonly', 'SELECT')\n",
      "('readwrite', 'INSERT')\n",
      "('readwrite', 'SELECT')\n",
      "('readwrite', 'UPDATE')\n",
      "('readwrite', 'DELETE')\n"
     ]
    }
   ],
   "source": [
    "### check database privileges for users and user groups ###\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT\n",
    "        rolname,\n",
    "        rolsuper,\n",
    "        rolcreaterole,\n",
    "        rolcreatedb,\n",
    "        rolcanlogin\n",
    "    FROM pg_roles\n",
    "    WHERE rolname IN ('readonly', 'readwrite', 'data_analyst', 'data_scientist');\"\"\")\n",
    "\n",
    "db_roles = cur.fetchall()\n",
    "for row in db_roles:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "    \n",
    "### check table privileges for user groups ###\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    SELECT\n",
    "        grantee,\n",
    "        privilege_type\n",
    "    FROM information_schema.table_privileges\n",
    "    WHERE grantee IN ('readonly', 'readwrite');\"\"\")\n",
    "\n",
    "privileges = cur.fetchall()\n",
    "for row in privileges:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, both of the user groups returned False for all the selected `pg_roles` columns, and both users returned False for all columns except `rolcanlogin`.\n",
    "\n",
    "Also, we can see that the correct privileges have been assigned to both user groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing the database, I am happy that all of the data from the `boston.csv` file has been entered, the two user groups with correct privileges have been created, and these privileges assigned to the correct users."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
